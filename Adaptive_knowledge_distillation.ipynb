{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YixhOuHa1gG4"
      },
      "source": [
        "# Knowledge Distillation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw-JZmBq1gG4"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yUgZCa-aLYQM",
        "outputId": "8e2b4662-b8fc-4672-c6e6-ec4d635b9005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-model-optimization in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.0)\n",
            "Requirement already satisfied: six~=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: numpy~=1.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-model-optimization) (1.26.4)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-model-optimization\n",
        "pip install larq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWkDJ5LD1gG5",
        "outputId": "24740da7-e6ff-4a08-ec58-298679c998a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow.python.framework import ops\n",
        "import numpy as np\n",
        "from tensorflow.keras import regularizers\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Lambda, Dropout\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import tempfile\n",
        "\n",
        "\n",
        "import larq as lq\n",
        "from larq.layers import QuantConv2D, QuantDense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XPPnSZg1gG5"
      },
      "source": [
        "## Distiller\n",
        "\n",
        "\n",
        "- A student loss function on the difference between student predictions and ground-truth\n",
        "- A distillation loss function, along with a `temperature`, on the difference between the\n",
        "soft student predictions and the soft teacher labels\n",
        "- An `alpha` factor to weight the student and distillation loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqRxT43FLYQQ"
      },
      "outputs": [],
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self.student(x, training=True)\n",
        "            teacher_pred = self.teacher(x, training=False)\n",
        "            student_loss = self.student_loss_fn(y, y_pred)\n",
        "\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_pred / self.temperature, axis=1),\n",
        "                tf.nn.softmax(y_pred / self.temperature, axis=1),\n",
        "            ) * (self.temperature**2)\n",
        "\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.student(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSu6R5Tj1gG6"
      },
      "source": [
        "## Create student and teacher models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBZouY0L1gG6"
      },
      "outputs": [],
      "source": [
        "# Create the teacher\n",
        "teacher = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 1)),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 1)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPool2D((2, 2)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPool2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPool2D((2, 2)),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu', kernel_initializer='he_uniform'),  # Match the student model\n",
        "        layers.Dense(256, activation='relu', kernel_initializer='he_uniform'),  # Match the student model\n",
        "        layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax'),\n",
        "    ],\n",
        "    name=\"teacher\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLKVgYmBLYQR"
      },
      "outputs": [],
      "source": [
        "student = keras.Sequential([\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "\n",
        "student_scratch = keras.Sequential([\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYpCdw7c1gG6"
      },
      "source": [
        "## Prepare the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08zILZObLYQT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Convert images to greyscale\n",
        "x_train = np.dot(x_train[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "x_test = np.dot(x_test[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 32, 32, 1))\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 32, 32, 1))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "num_classes = 10  # Replace with the number of classes in your problem\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im5F-YOw1gG7"
      },
      "source": [
        "## Train the teacher\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XnIOeyX1gG7",
        "outputId": "1ebd9db4-670b-412c-800e-ae3ab6f98747",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5531: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 17s 9ms/step - loss: 1.9536 - categorical_accuracy: 0.2889 - val_loss: 1.5173 - val_categorical_accuracy: 0.4570\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3910 - categorical_accuracy: 0.5193 - val_loss: 1.1341 - val_categorical_accuracy: 0.6001\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1060 - categorical_accuracy: 0.6295 - val_loss: 0.9480 - val_categorical_accuracy: 0.6769\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.9584 - categorical_accuracy: 0.6802 - val_loss: 0.8193 - val_categorical_accuracy: 0.7199\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8615 - categorical_accuracy: 0.7141 - val_loss: 0.7828 - val_categorical_accuracy: 0.7378\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7930 - categorical_accuracy: 0.7384 - val_loss: 0.6985 - val_categorical_accuracy: 0.7625\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7280 - categorical_accuracy: 0.7617 - val_loss: 0.7405 - val_categorical_accuracy: 0.7577\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6672 - categorical_accuracy: 0.7826 - val_loss: 0.7483 - val_categorical_accuracy: 0.7568\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6259 - categorical_accuracy: 0.7937 - val_loss: 0.6447 - val_categorical_accuracy: 0.7929\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5837 - categorical_accuracy: 0.8085 - val_loss: 0.6426 - val_categorical_accuracy: 0.8005\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5495 - categorical_accuracy: 0.8185 - val_loss: 0.6678 - val_categorical_accuracy: 0.7912\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5200 - categorical_accuracy: 0.8317 - val_loss: 0.6296 - val_categorical_accuracy: 0.8032\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4876 - categorical_accuracy: 0.8414 - val_loss: 0.6648 - val_categorical_accuracy: 0.7977\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4555 - categorical_accuracy: 0.8503 - val_loss: 0.6613 - val_categorical_accuracy: 0.8042\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4429 - categorical_accuracy: 0.8571 - val_loss: 0.6663 - val_categorical_accuracy: 0.8040\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4081 - categorical_accuracy: 0.8670 - val_loss: 0.6475 - val_categorical_accuracy: 0.8150\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3879 - categorical_accuracy: 0.8747 - val_loss: 0.6744 - val_categorical_accuracy: 0.8080\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3723 - categorical_accuracy: 0.8799 - val_loss: 0.6675 - val_categorical_accuracy: 0.8102\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3498 - categorical_accuracy: 0.8872 - val_loss: 0.7297 - val_categorical_accuracy: 0.8050\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3305 - categorical_accuracy: 0.8937 - val_loss: 0.6682 - val_categorical_accuracy: 0.8199\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6708 - categorical_accuracy: 0.8177\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6708458065986633, 0.8177000284194946]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train teacher as usual\n",
        "teacher.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate teacher on data.\n",
        "teacher.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))\n",
        "teacher.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cYinHkJLYQU"
      },
      "source": [
        "# Sort data from easy to hard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwaXR5WzJ5DN"
      },
      "outputs": [],
      "source": [
        "def curriculum_sort(x_train, y_train):\n",
        "    # sort based on the entropy of the teacher's predictions\n",
        "    teacher_preds = teacher.predict(x_train)\n",
        "    entropies = -np.sum(teacher_preds * np.log(teacher_preds + 1e-10), axis=1)\n",
        "    sorted_indices = np.argsort(entropies)\n",
        "    return sorted_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeJPkYeGJ-aH",
        "outputId": "167e8119-529b-460a-e2db-f105112cf927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 3s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Sort the training data based on the curriculum\n",
        "sorted_indices = curriculum_sort(x_train, y_train)\n",
        "x_train = x_train[sorted_indices]\n",
        "y_train = y_train[sorted_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agaW4nnZ1gG7"
      },
      "source": [
        "## Distill teacher to student\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KZkQywLKLYQW",
        "outputId": "6c2586ae-f865-4d0f-9570-bbb0ea2b4c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3028 - categorical_accuracy: 0.0986 - val_loss: 2.3028 - val_categorical_accuracy: 0.1023\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - categorical_accuracy: 0.1004 - val_loss: 2.3028 - val_categorical_accuracy: 0.0933\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - categorical_accuracy: 0.0990 - val_loss: 2.3028 - val_categorical_accuracy: 0.0979\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - categorical_accuracy: 0.0993 - val_loss: 2.3029 - val_categorical_accuracy: 0.0933\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - categorical_accuracy: 0.0992 - val_loss: 2.3029 - val_categorical_accuracy: 0.0933\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3027 - categorical_accuracy: 0.1013 - val_loss: 2.3028 - val_categorical_accuracy: 0.1015\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - categorical_accuracy: 0.0987 - val_loss: 2.3028 - val_categorical_accuracy: 0.0933\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3027 - categorical_accuracy: 0.0989 - val_loss: 2.3027 - val_categorical_accuracy: 0.0933\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3028 - categorical_accuracy: 0.1025 - val_loss: 2.3027 - val_categorical_accuracy: 0.0973\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - categorical_accuracy: 0.0989 - val_loss: 2.3028 - val_categorical_accuracy: 0.0933\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ee95f20700>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "student.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        "\n",
        "student.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiy0jbJsLYQX",
        "outputId": "08e2a272-0a2a-407b-af4b-3af55afeb383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - categorical_accuracy: 0.1000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.302635431289673, 0.10000000149011612]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "student.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "j7XznIHzLYQX",
        "outputId": "02a9e7f9-7d65-4fe3-951d-4d4bc4092b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 9s 13ms/step - categorical_accuracy: 0.1019 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0994\n",
            "Student Loss: 2.3026, Temperature: 6.00, Alpha: 0.90\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 8s 14ms/step - categorical_accuracy: 0.0999 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 4.86, Alpha: 0.86\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1008 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 4.20, Alpha: 0.81\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.0993 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 3.72, Alpha: 0.77\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1002 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 3.36, Alpha: 0.74\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 8s 14ms/step - categorical_accuracy: 0.1000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 3.06, Alpha: 0.70\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.0985 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 2.80, Alpha: 0.67\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1011 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 2.58, Alpha: 0.63\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1001 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 2.39, Alpha: 0.60\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.0992 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 2.22, Alpha: 0.57\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.0989 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 2.06, Alpha: 0.55\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1005 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0973\n",
            "Student Loss: 2.3026, Temperature: 1.92, Alpha: 0.52\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1005 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 1.79, Alpha: 0.49\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1000 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 1.67, Alpha: 0.47\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1004 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 1.55, Alpha: 0.45\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.1014 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 1.45, Alpha: 0.43\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.0996 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 1.35, Alpha: 0.40\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.0991 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0973\n",
            "Student Loss: 2.3026, Temperature: 1.25, Alpha: 0.38\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.0984 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 1.16, Alpha: 0.37\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 8s 13ms/step - categorical_accuracy: 0.0999 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0933\n",
            "Student Loss: 2.3026, Temperature: 1.08, Alpha: 0.35\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.1000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.0, 0.10000000149011612]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_temp = 6\n",
        "final_temp = 1\n",
        "initial_alpha = 0.9\n",
        "final_alpha = 0.1\n",
        "decay_rate = 1\n",
        "loss_scale = 2\n",
        "\n",
        "\n",
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student, teacher=teacher)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.CategoricalCrossentropy(),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.9,\n",
        "    temperature=6,\n",
        ")\n",
        "\n",
        "\n",
        "def alpha_schedule(epoch):\n",
        "   # Returns exponentially decaying alpha\n",
        "   return initial_alpha * np.exp(-epoch / num_epochs)\n",
        "\n",
        "def temp_schedule(epoch):\n",
        "    # Returns logarithmically increasing temperature\n",
        "#     return initial_temp + (final_temp - initial_temp) * np.log1p(epoch) / np.log1p(num_epochs)\n",
        "    return final_temp + (initial_temp - final_temp) * (1 - np.log1p(epoch) / np.log1p(num_epochs))\n",
        "\n",
        "# Temperature annealing\n",
        "num_epochs = 20\n",
        "# temp_step = (initial_temp - final_temp) / num_epochs\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "# def adaptive_temperature(student_loss, initial_temp, final_temp, decay_rate):\n",
        "#     return final_temp + (initial_temp - final_temp) * np.exp(-decay_rate * student_loss)\n",
        "\n",
        "# def adaptive_temperature(student_loss, initial_temp, final_temp, decay_rate, loss_scale):\n",
        "#     return final_temp + (initial_temp - final_temp) * np.exp(-decay_rate * student_loss * loss_scale)\n",
        "\n",
        "# def adaptive_alpha(student_loss, initial_alpha, final_alpha, decay_rate, loss_scale):\n",
        "#     return final_alpha + (initial_alpha - final_alpha) * np.exp(-decay_rate * student_loss * loss_scale)\n",
        "\n",
        "\n",
        "\n",
        "# def adaptive_temperature(student_loss, initial_temp, final_temp, decay_rate, loss_scale):\n",
        "#     return initial_temp - (initial_temp - final_temp) * decay_rate * (student_loss / loss_scale)\n",
        "\n",
        "# def adaptive_alpha(student_loss, initial_alpha, final_alpha, decay_rate, loss_scale):\n",
        "#     return initial_alpha - (initial_alpha - final_alpha) * decay_rate * (student_loss / loss_scale)\n",
        "\n",
        "def adaptive_temperature(student_loss, initial_temp, final_temp, decay_rate):\n",
        "    return initial_temp - (initial_temp - final_temp) * decay_rate * student_loss\n",
        "\n",
        "def adaptive_alpha(student_loss, initial_alpha, final_alpha, decay_rate):\n",
        "    return initial_alpha - (initial_alpha - final_alpha) * decay_rate * student_loss\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Perform data augmentation\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "\n",
        "\n",
        "    alpha = alpha_schedule(epoch)\n",
        "    temperature = temp_schedule(epoch)\n",
        "    distiller.temperature = temperature\n",
        "    distiller.alpha = alpha\n",
        "\n",
        "    epoch_student_loss = 0\n",
        "\n",
        "    # Iterate over the training data in batches\n",
        "    for batch_start in range(0, len(x_train), batch_size):\n",
        "        batch_end = min(batch_start + batch_size, len(x_train))\n",
        "        x_batch = x_train[batch_start:batch_end]\n",
        "        y_batch = y_train[batch_start:batch_end]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            student_predictions = distiller.student(x_batch)\n",
        "\n",
        "            # Calculate student loss for the batch\n",
        "            student_loss = distiller.student_loss_fn(y_batch, student_predictions)\n",
        "\n",
        "        # Accumulate student loss for the epoch\n",
        "        epoch_student_loss += student_loss.numpy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate average student loss for the epoch\n",
        "    epoch_student_loss /= (len(x_train) // batch_size)\n",
        "\n",
        "#     Calculate adaptive temperature\n",
        "#     adaptive_temp_value = adaptive_temperature(epoch_student_loss, initial_temp, final_temp, decay_rate)\n",
        "#     adaptive_alpha_value = adaptive_alpha(epoch_student_loss, initial_alpha, final_alpha, decay_rate)\n",
        "\n",
        "#     Update distiller's temperature (used for adaptive)\n",
        "#     distiller.temperature = adaptive_temp_value\n",
        "#     distiller.alpha = adaptive_alpha_value\n",
        "\n",
        "    # Train the model for one epoch\n",
        "    model = distiller.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                  steps_per_epoch=len(x_train) // batch_size,\n",
        "                  validation_data=(x_val, y_val))\n",
        "\n",
        "\n",
        "    print(f\"Student Loss: {epoch_student_loss:.4f}, Temperature: {temperature:.2f}, Alpha: {alpha:.2f}\")\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYvCZ5kRLYQX"
      },
      "source": [
        "# Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JTAKbifLYQY",
        "outputId": "5a629e48-f2e8-4545-dad2-9fb423943346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 102s 80ms/step - loss: 2.3027 - categorical_accuracy: 0.1019 - val_loss: 2.3030 - val_categorical_accuracy: 0.0996\n"
          ]
        }
      ],
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "# Define the pruning schedule\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=len(x_train) * 10)\n",
        "}\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_model = prune_low_magnitude(distiller.student, **pruning_params)\n",
        "\n",
        "pruning_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "pruning_callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    pruning_model.fit(x_train, y_train, epochs=1, validation_data=(x_val, y_val), callbacks=pruning_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crlYDMpKLYQY",
        "outputId": "a9324061-5429-4390-d048-595913cc0ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3027 - categorical_accuracy: 0.1000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.302705764770508, 0.10000000149011612]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pruning_model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQo81QTNLYQY"
      },
      "outputs": [],
      "source": [
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruning_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ0HB2aFLYQY",
        "outputId": "82f2030b-bcbc-4204-d149-0983f6799400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " depthwise_conv2d_26 (Depthw  (None, 30, 30, 1)        10        \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 30, 30, 64)        128       \n",
            "                                                                 \n",
            " depthwise_conv2d_27 (Depthw  (None, 28, 28, 64)       640       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 128)       8320      \n",
            "                                                                 \n",
            " depthwise_conv2d_28 (Depthw  (None, 26, 26, 128)      1280      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 26, 26, 512)       66048     \n",
            "                                                                 \n",
            " global_average_pooling2d_10  (None, 512)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,556\n",
            "Trainable params: 81,556\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "stripped_pruned_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIVrclBULYQZ"
      },
      "source": [
        "# Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "JtnCG5_FLYQZ",
        "outputId": "ba59992a-a80d-4e2a-8a16-8fe5b3e109b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 55s 43ms/step - loss: 2.3027 - categorical_accuracy: 0.1006 - val_loss: 2.3029 - val_categorical_accuracy: 0.0933\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 2.3027 - categorical_accuracy: 0.0998 - val_loss: 2.3029 - val_categorical_accuracy: 0.0933\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 2.3028 - categorical_accuracy: 0.0995 - val_loss: 2.3028 - val_categorical_accuracy: 0.0933\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 2.3028 - categorical_accuracy: 0.1006 - val_loss: 2.3030 - val_categorical_accuracy: 0.0933\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 54s 43ms/step - loss: 2.3027 - categorical_accuracy: 0.0986 - val_loss: 2.3030 - val_categorical_accuracy: 0.0933\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 2.3028 - categorical_accuracy: 0.0987 - val_loss: 2.3031 - val_categorical_accuracy: 0.0979\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 2.3028 - categorical_accuracy: 0.1004 - val_loss: 2.3033 - val_categorical_accuracy: 0.0979\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 2.3028 - categorical_accuracy: 0.0993 - val_loss: 2.3033 - val_categorical_accuracy: 0.0973\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 54s 43ms/step - loss: 2.3028 - categorical_accuracy: 0.1003 - val_loss: 2.3034 - val_categorical_accuracy: 0.0973\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 54s 44ms/step - loss: 2.3029 - categorical_accuracy: 0.1007 - val_loss: 2.3035 - val_categorical_accuracy: 0.0973\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ee8627ee80>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply quantization-aware training to the student model\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "student_quant = quantize_model(stripped_pruned_model)\n",
        "\n",
        "# Compile the quantized student model\n",
        "student_quant.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        ")\n",
        "# Fine-tune the quantized student model\n",
        "student_quant.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54pui8JJLYQZ",
        "outputId": "c9f4ad97-6736-497a-dc00-c91db37da299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 5s 15ms/step - loss: 2.3029 - categorical_accuracy: 0.1000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.302885055541992, 0.10000000149011612]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "student_quant.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlJCMNi2LYQa",
        "outputId": "9a8308cf-141e-4548-d581-0b74cd68f078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 32, 32, 1)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_depthwise_conv2d_26 (  (None, 30, 30, 1)        15        \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_conv2d_9 (QuantizeWra  (None, 30, 30, 64)       259       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_depthwise_conv2d_27 (  (None, 28, 28, 64)       645       \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_conv2d_10 (QuantizeWr  (None, 28, 28, 128)      8579      \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_depthwise_conv2d_28 (  (None, 26, 26, 128)      1285      \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_conv2d_11 (QuantizeWr  (None, 26, 26, 512)      67075     \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_global_average_poolin  (None, 512)              3         \n",
            " g2d_10 (QuantizeWrapperV2)                                      \n",
            "                                                                 \n",
            " quant_dense_14 (QuantizeWra  (None, 10)               5135      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,999\n",
            "Trainable params: 81,556\n",
            "Non-trainable params: 1,443\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "student_quant.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noXuNS-jLYQc"
      },
      "source": [
        "# Final output before softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ib1_bTiLYQc"
      },
      "outputs": [],
      "source": [
        "model_final = keras.models.Sequential(student_quant.layers[0:-1])\n",
        "model_final.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "input_shape = distiller.student.layers[0].input_shape\n",
        "\n",
        "model_final.build(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZXypPecLYQc",
        "outputId": "caff1c70-dbbe-45ce-bbaa-011b335873b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 32, 32, 1)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_depthwise_conv2d_26 (  (None, 30, 30, 1)        15        \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_conv2d_9 (QuantizeWra  (None, 30, 30, 64)       259       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_depthwise_conv2d_27 (  (None, 28, 28, 64)       645       \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_conv2d_10 (QuantizeWr  (None, 28, 28, 128)      8579      \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_depthwise_conv2d_28 (  (None, 26, 26, 128)      1285      \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_conv2d_11 (QuantizeWr  (None, 26, 26, 512)      67075     \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_global_average_poolin  (None, 512)              3         \n",
            " g2d_10 (QuantizeWrapperV2)                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,864\n",
            "Trainable params: 76,426\n",
            "Non-trainable params: 1,438\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_final.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuoZLu6rLYQd",
        "outputId": "73c05943-e3c4-4917-800c-b0c9522112d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 155ms/step\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "x_example = x_test[0]\n",
        "x_example = np.expand_dims(x_example, axis=0)\n",
        "intermediate_output = model_final.predict(x_example)\n",
        "print(intermediate_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrX4xWcKLYQe",
        "outputId": "bd7c1f24-d1d0-4f43-80ec-c7328aabcc82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as depthwise_conv2d_26_layer_call_fn, depthwise_conv2d_26_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_9_layer_call_fn, conv2d_9_layer_call_and_return_conditional_losses while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\CMP3WO~1\\AppData\\Local\\Temp\\tmpukcvtp17\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\CMP3WO~1\\AppData\\Local\\Temp\\tmpukcvtp17\\assets\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantized model in Mb: 0.1021728515625\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_final)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_tflite_model = converter.convert()\n",
        "# Create float TFLite model.\n",
        "_, quant_file = tempfile.mkstemp('.tflite')\n",
        "with open(quant_file, 'wb') as f:\n",
        "  f.write(quantized_tflite_model)\n",
        "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtCjovS9LYQe",
        "outputId": "6bc9c355-bc59-4d03-b777-f0c2fdfafb91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "107136"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "open(\"CNN_512_grey_depth.tflite\", \"wb\").write(quantized_tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baWI9Asb1gG7"
      },
      "source": [
        "## Train student from scratch for comparison\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuMf-BQ61gG7",
        "outputId": "cf1d39bc-7112-40f0-a290-936c494e7fc0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 1.7834 - categorical_accuracy: 0.3086 - val_loss: 1.6252 - val_categorical_accuracy: 0.3764\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.5030 - categorical_accuracy: 0.4345 - val_loss: 1.3970 - val_categorical_accuracy: 0.4782\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3549 - categorical_accuracy: 0.5005 - val_loss: 1.3393 - val_categorical_accuracy: 0.5019\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2419 - categorical_accuracy: 0.5489 - val_loss: 1.1761 - val_categorical_accuracy: 0.5714\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1593 - categorical_accuracy: 0.5812 - val_loss: 1.1469 - val_categorical_accuracy: 0.5914\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0957 - categorical_accuracy: 0.6052 - val_loss: 1.0283 - val_categorical_accuracy: 0.6315\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0331 - categorical_accuracy: 0.6296 - val_loss: 1.0808 - val_categorical_accuracy: 0.6192\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.9784 - categorical_accuracy: 0.6481 - val_loss: 0.9882 - val_categorical_accuracy: 0.6504\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.9294 - categorical_accuracy: 0.6674 - val_loss: 1.0039 - val_categorical_accuracy: 0.6436\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8857 - categorical_accuracy: 0.6839 - val_loss: 0.8752 - val_categorical_accuracy: 0.6888\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8418 - categorical_accuracy: 0.7033 - val_loss: 0.8516 - val_categorical_accuracy: 0.7025\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8068 - categorical_accuracy: 0.7134 - val_loss: 0.8507 - val_categorical_accuracy: 0.6994\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7733 - categorical_accuracy: 0.7249 - val_loss: 0.8643 - val_categorical_accuracy: 0.6972\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7318 - categorical_accuracy: 0.7404 - val_loss: 0.9043 - val_categorical_accuracy: 0.6846\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6996 - categorical_accuracy: 0.7523 - val_loss: 0.8535 - val_categorical_accuracy: 0.7033\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6746 - categorical_accuracy: 0.7609 - val_loss: 0.7832 - val_categorical_accuracy: 0.7271\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6426 - categorical_accuracy: 0.7740 - val_loss: 0.7521 - val_categorical_accuracy: 0.7382\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6094 - categorical_accuracy: 0.7838 - val_loss: 0.8280 - val_categorical_accuracy: 0.7129\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5759 - categorical_accuracy: 0.7956 - val_loss: 0.7683 - val_categorical_accuracy: 0.7447\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5505 - categorical_accuracy: 0.8051 - val_loss: 0.7967 - val_categorical_accuracy: 0.7313\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7912 - categorical_accuracy: 0.7263\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.7911658883094788, 0.7263000011444092]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train student as doen usually\n",
        "student_scratch.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate student trained from scratch.\n",
        "student_scratch.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))\n",
        "student_scratch.evaluate(x_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}